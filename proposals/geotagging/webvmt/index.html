<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html
  PUBLIC "-//W3C//DTD XHTML 1.1 plus MathML 2.0//EN" "http://www.w3.org/Math/DTD/mathml2/xhtml-math11-f.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"><!--This file was converted to xhtml by OpenOffice.org - see http://xml.openoffice.org/odf2xhtml for more info.--><head profile="http://dublincore.org/documents/dcmi-terms/"><meta http-equiv="Content-Type" content="application/xhtml+xml; charset=utf-8"/><title xml:lang="en-US">WebVMT: The Web Video Map Tracks Format</title><meta name="DCTERMS.title" content="WebVMT: The Web Video Map Tracks Format" xml:lang="en-US"/><meta name="DCTERMS.language" content="en-US" scheme="DCTERMS.RFC4646"/><meta name="DCTERMS.source" content="http://xml.openoffice.org/odf2xhtml"/><meta name="DCTERMS.creator" content="Rob Smith"/><meta name="DCTERMS.issued" content="2018-02-09T15:05:49" scheme="DCTERMS.W3CDTF"/><meta name="DCTERMS.contributor" content="Rob Smith"/><meta name="DCTERMS.modified" content="2018-03-02T17:13:56" scheme="DCTERMS.W3CDTF"/><meta name="DCTERMS.provenance" content="" xml:lang="en-US"/><meta name="DCTERMS.subject" content=", video geotagging maps" xml:lang="en-US"/><link rel="schema.DC" href="http://purl.org/dc/elements/1.1/" hreflang="en"/><link rel="schema.DCTERMS" href="http://purl.org/dc/terms/" hreflang="en"/><link rel="schema.DCTYPE" href="http://purl.org/dc/dcmitype/" hreflang="en"/><link rel="schema.DCAM" href="http://purl.org/dc/dcam/" hreflang="en"/><style type="text/css">
	@page {  }
	table { border-collapse:collapse; border-spacing:0; empty-cells:show }
	td, th { vertical-align:top; font-size:12pt;}
	h1, h2, h3, h4, h5, h6 { clear:both }
	ol, ul { margin:0; padding:0;}
	li { list-style: none; margin:0; padding:0;}
	<!-- "li span.odfLiEnd" - IE 7 issue-->
	li span. { clear: both; line-height:0; width:0; height:0; margin:0; padding:0; }
	span.footnodeNumber { padding-right:1em; }
	span.annotation_style_by_filter { font-size:95%; font-family:Arial; background-color:#fff000;  margin:0; border:0; padding:0;  }
	* { margin:0;}
	.Contents_20_1 { font-size:11pt; font-family:Arial; writing-mode:page; margin-left:0cm; margin-right:0cm; text-indent:0cm; }
	.Contents_20_2 { font-size:11pt; font-family:Arial; writing-mode:page; margin-left:0.499cm; margin-right:0cm; text-indent:0cm; }
	.Contents_20_3 { font-size:11pt; font-family:Arial; writing-mode:page; margin-left:0.998cm; margin-right:0cm; text-indent:0cm; }
	.Contents_20_4 { font-size:11pt; font-family:Arial; writing-mode:page; margin-left:1.498cm; margin-right:0cm; text-indent:0cm; }
	.Contents_20_Heading { font-size:16pt; margin-bottom:0.212cm; margin-top:0.423cm; font-family:Arial; writing-mode:page; margin-left:0cm; margin-right:0cm; text-indent:0cm; font-weight:bold; }
	.Heading_20_1 { font-size:125%; margin-bottom:0.212cm; margin-top:0.423cm; font-family:Arial; writing-mode:page; font-weight:bold; }
	.Heading_20_2 { font-size:115%; margin-bottom:0.212cm; margin-top:0.423cm; font-family:Arial; writing-mode:page; font-style:normal; font-weight:bold; }
	.Heading_20_3 { font-size:11pt; margin-bottom:0.212cm; margin-top:0.423cm; font-family:Arial; writing-mode:page; font-weight:bold; }
	.List_20_1 { font-size:11pt; margin-bottom:0.212cm; margin-left:0.635cm; margin-right:0cm; margin-top:0cm; text-indent:-0.635cm; font-family:Arial; writing-mode:page; }
	.P1 { font-size:11pt; margin-bottom:0.212cm; margin-top:0cm; font-family:Arial; writing-mode:page; }
	.P10 { font-size:11pt; margin-bottom:0.212cm; margin-top:0cm; font-family:Arial; writing-mode:page; margin-left:-0.023cm; margin-right:0cm; text-indent:0cm; }
	.P11 { font-size:11pt; margin-bottom:0.212cm; margin-top:0cm; font-family:Arial; writing-mode:page; margin-left:1.251cm; margin-right:0cm; text-indent:0cm; }
	.P12 { font-size:11pt; margin-bottom:0.212cm; margin-top:0cm; font-family:Courier; writing-mode:page; margin-left:1.251cm; margin-right:0cm; text-indent:0cm; }
	.P13 { font-size:11pt; margin-bottom:0.212cm; margin-top:0cm; font-family:Courier; writing-mode:page; margin-left:1.251cm; margin-right:0cm; text-indent:0cm; font-weight:normal; }
	.P14 { font-size:11pt; font-style:normal; font-weight:bold; margin-bottom:0.212cm; margin-top:0.423cm; font-family:Arial; writing-mode:page; }
	.P15 { font-size:11pt; font-style:italic; font-weight:bold; margin-bottom:0.212cm; margin-top:0cm; font-family:Arial; writing-mode:page; }
	.P16 { font-size:11pt; margin-left:0cm; margin-right:0cm; text-indent:0cm; font-family:Arial; writing-mode:page; }
	.P17 { font-size:11pt; margin-left:0.499cm; margin-right:0cm; text-indent:0cm; font-family:Arial; writing-mode:page; }
	.P18 { font-size:11pt; margin-left:0.998cm; margin-right:0cm; text-indent:0cm; font-family:Arial; writing-mode:page; }
	.P19 { font-size:11pt; margin-bottom:0.212cm; margin-left:0.635cm; margin-right:0cm; margin-top:0cm; text-indent:-0.635cm; font-family:Arial; writing-mode:page; }
	.P2 { font-size:11pt; margin-bottom:0.212cm; margin-top:0cm; font-family:Arial; writing-mode:page; text-align:left ! important; }
	.P3 { font-size:11pt; margin-bottom:0.212cm; margin-top:0cm; font-family:Arial; writing-mode:page; font-weight:normal; }
	.P4 { font-size:11pt; margin-bottom:0.212cm; margin-top:0cm; font-family:Arial; writing-mode:page; font-style:normal; }
	.P5 { font-size:11pt; margin-bottom:0.212cm; margin-top:0cm; font-family:Arial; writing-mode:page; text-align:left ! important; font-weight:bold; }
	.P6 { font-size:14pt; margin-bottom:0.212cm; margin-top:0cm; font-family:Arial; writing-mode:page; text-align:left ! important; font-weight:bold; }
	.P7 { font-size:20pt; margin-bottom:0.212cm; margin-top:0cm; font-family:Arial; writing-mode:page; text-align:left ! important; font-weight:bold; }
	.P8 { font-size:16pt; margin-bottom:0.212cm; margin-top:0cm; font-family:Arial; writing-mode:page; text-align:left ! important; font-weight:bold; }
	.P9 { font-size:14pt; margin-bottom:0.212cm; margin-top:0cm; font-family:Arial; writing-mode:page; text-align:left ! important; font-weight:bold; }
	.Text_20_body { font-size:11pt; font-family:Arial; writing-mode:page; margin-top:0cm; margin-bottom:0.212cm; }
	.Sect1 { background-color:transparent; }
	.Internet_20_link { font-family:Arial; font-size:11pt; text-decoration:underline; }
	.T1 { font-weight:normal; }
	.T2 { font-family:Arial; }
	.T3 { font-family:Arial; font-size:11pt; }
	.T4 { font-family:Courier; font-size:11pt; font-weight:normal; }
	.T5 { font-family:Courier; font-size:11pt; }
	.T6 { font-style:normal; }
	<!-- ODF styles with no properties representable as CSS -->
	.Sect2 .Numbering_20_Symbols { }
	</style></head><body dir="ltr" style="max-width:21.001cm;margin-top:2cm; margin-bottom:2cm; margin-left:2cm; margin-right:2cm; "><p class="P7">WebVMT: The Web Video Map Tracks Format</p><p class="P8">Explanatory Specification: 28 February 2018</p><p class="P5">This version:</p><p class="P2"><a href="https://github.com/w3c/sdw/proposals/geotagging/webvmt" class="Internet_20_link">https://github.com/w3c/sdw/proposals/geotagging/webvmt</a></p><p class="P5">Latest published version:</p><p class="P2"><a href="https://github.com/w3c/sdw/proposals/geotagging/webvmt" class="Internet_20_link">https://github.com/w3c/sdw/proposals/geotagging/webvmt</a></p><p class="P5">Editor:</p><p class="P2">Rob Smith (Away Team Software Ltd)</p><p class="P2"> </p><p class="P9">Abstract</p><p class="P2">This specification defines WebVMT, the Web Video Map Tracks format, which is an enabling technology whose main use is for marking up external map track resources in connection with the HTML &lt;track&gt; element. WebVMT files provide map presentation and annotation synchronised to video content, including animation support, and more generally any form of geolocation data that is time-aligned with audio or video content.</p><p class="P2"> </p><p class="P6">Status of this Document</p><p class="P2">This specification was published by the <a href="https://www.w3.org/2017/sdwig/" class="Internet_20_link">Spatial Data on the Web Interest Group</a>. It is not a W3C Standard nor is it on the W3C Standards Track.</p><p class="P2">Work on this specification is being overseen by the Spatial Data on the Web Interest Group. This group identify areas where standards should be developed jointly by both W3C and the Open Geospatial Consortium (OGC).</p><p class="P2">If you wish to make comments regarding this document, please send them to <a href="mailto:public-sdwig@w3.org" class="Internet_20_link">public-sdwig@w3.org</a>, or subscribe via the <a href="https://lists.w3.org/Archives/Public/public-sdwig/" class="Internet_20_link">archives</a> webpage.</p><p class="P2"> </p><table border="0" cellspacing="0" cellpadding="0" class="Sect1"><colgroup/><p class="Contents_20_Heading">Table of Contents</p><tr><td><p class="P16"><a href="#__RefHeading__1641_378428891">1 Use Cases</a></p></td></tr><tr><td><p class="P17"><a href="#__RefHeading__1643_378428891">1.1 Coastguard/Mountain Rescue</a></p></td></tr><tr><td><p class="P17"><a href="#__RefHeading__1645_378428891">1.2 Area Survey</a></p></td></tr><tr><td><p class="P17"><a href="#__RefHeading__1647_378428891">1.3 Outdoor Trails</a></p></td></tr><tr><td><p class="P17"><a href="#__RefHeading__1649_378428891">1.4 TV Sports Coverage</a></p></td></tr><tr><td><p class="P17"><a href="#__RefHeading__1651_378428891">1.5 Proxy Explorer</a></p></td></tr><tr><td><p class="P17"><a href="#__RefHeading__1653_378428891">1.6 Treasure Hunt</a></p></td></tr><tr><td><p class="P17"><a href="#__RefHeading__1655_378428891">1.7 Swarm Monitoring</a></p></td></tr><tr><td><p class="P16"><a href="#__RefHeading__1657_378428891">2 State of the Art</a></p></td></tr><tr><td><p class="P17"><a href="#__RefHeading__1659_378428891">2.1 Current Solutions</a></p></td></tr><tr><td><p class="P17"><a href="#__RefHeading__1661_378428891">2.2 Growing Requirement</a></p></td></tr><tr><td><p class="P17"><a href="#__RefHeading__1663_378428891">2.3 Accessible Standard Opportunity</a></p></td></tr><tr><td><p class="P16"><a href="#__RefHeading__1665_378428891">3 Proposed Solution</a></p></td></tr><tr><td><p class="P17"><a href="#__RefHeading__1667_378428891">3.1 Map Cues</a></p></td></tr><tr><td><p class="P18"><a href="#__RefHeading__1669_378428891">3.1.1 Example 1: Hello World</a></p></td></tr><tr><td><p class="P18"><a href="#__RefHeading__1671_378428891">3.1.2 Example 2: Map Presentation</a></p></td></tr><tr><td><p class="P17"><a href="#__RefHeading__1673_378428891">3.2 Comments</a></p></td></tr><tr><td><p class="P18"><a href="#__RefHeading__1675_378428891">3.2.1 Example 3: Comment Block (as WebVTT)</a></p></td></tr><tr><td><p class="P17"><a href="#__RefHeading__1677_378428891">3.3 Styling</a></p></td></tr><tr><td><p class="P18"><a href="#__RefHeading__1679_378428891">3.3.1 Example 4: CSS Style in HTML</a></p></td></tr><tr><td><p class="P18"><a href="#__RefHeading__1681_378428891">3.3.2 Example 5: CSS Style Block (as WebVTT)</a></p></td></tr><tr><td><p class="P17"><a href="#__RefHeading__1683_378428891">3.4 Animation</a></p></td></tr><tr><td><p class="P18"><a href="#__RefHeading__1685_378428891">3.4.1 Example 6: Animated Path</a></p></td></tr><tr><td><p class="P18"><a href="#__RefHeading__1687_378428891">3.4.2 Example 7: Animated Annotation</a></p></td></tr><tr><td><p class="P16"><a href="#__RefHeading__1689_378428891">4 Known Issues</a></p></td></tr><tr><td><p class="P17"><a href="#__RefHeading__1691_378428891">4.1 Planned Features</a></p></td></tr><tr><td><p class="P18"><a href="#__RefHeading__1693_378428891">4.1.1 Marker</a></p></td></tr><tr><td><p class="P18"><a href="#__RefHeading__1695_378428891">4.1.2 Label</a></p></td></tr><tr><td><p class="P18"><a href="#__RefHeading__1697_378428891">4.1.3 Tile URL Shortcut</a></p></td></tr><tr><td><p class="P18"><a href="#__RefHeading__1804_378428891">4.1.4 Layer</a></p></td></tr><tr><td><p class="P18"><a href="#__RefHeading__1806_378428891">4.1.5 Multiple APIs</a></p></td></tr><tr><td><p class="P18"><a href="#__RefHeading__1808_378428891">4.1.6 Camera Direction</a></p></td></tr></table><h1 class="Heading_20_1"><a id="a_1__Use_Cases"><span>1 </span></a><a name="__RefHeading__1641_378428891"/>Use Cases</h1><p class="P1">Example scenarios in which WebVMT can add significant value, with a list of identified benefits.</p><h2 class="Heading_20_2"><a id="a_1_1__Coastguard_Mountain_Rescue"><span>1.1 </span></a><a name="__RefHeading__1643_378428891"/>Coastguard/Mountain Rescue</h2><p class="P1">A missing person is reported to the rescue services, who deploy a drone to search inaccessible areas of coastline or moorland for their target. The drone relays back a live video stream from its camera and geolocation data from its GPS receiver to a remote human operator who is piloting it.</p><p class="P1">As the search continues, the operator spots a target on the video feed and can instantly call up an electronic map, synchronised to the video, which has been automatically following the drone’s position and plotting its ground track. The display gives the operator immediate context for the video, and allows them to override the automatic map control and zoom in to pinpoint the target’s precise location from the features visible in the video and on the map/satellite view. They mark the location and then zoom out to assess the surrounding terrain and advise the recovery team of the best approach to the target. For example, the terrain may dictate very different approach routes if either the person has twisted their ankle at the top of a cliff, or has fallen and is lying at the bottom of the same cliff, though the co-ordinates are almost identical in both cases.</p><p class="P1">The operator has been able to make important decisions quickly, which may be life critical, and deploy recovery resources effectively.</p><ul><li><p class="P19" style="margin-left:0.635cm;"><span class="Numbering_20_Symbols" style="display:block;float:left;min-width:0cm">•</span>  Rapid decision making;<span class="odfLiEnd"/> </p></li><li><p class="List_20_1" style="margin-left:0.635cm;"><span class="Numbering_20_Symbols" style="display:block;float:left;min-width:0cm">•</span>  Effective resource deployment.<span class="odfLiEnd"/> </p></li></ul><h2 class="Heading_20_2"><a id="a_1_2__Area_Survey"><span>1.2 </span></a><a name="__RefHeading__1645_378428891"/>Area Survey</h2><p class="P1">A survey drone is equipped with a camera which records an image of the ground directly below it. The pilot is a remote human operator, tasked with surveying a defined area from particular height in order to capture the required data.</p><p class="P1">As the survey progresses, geometric shapes are automatically added to the map to represent areas which have been included. Once the pilot has complete their sweep, they can quickly confirm whether the whole area required has been covered. If any areas have been missed, the pilot can use the map to navigate and make additional passes to fill the gaps, before returning to base.</p><p class="P1">The operator has been easily able to verify the quality of their own work and correct any errors, saving time and additional effort in redeployment.</p><ul><li><p class="List_20_1" style="margin-left:0.635cm;"><span class="Numbering_20_Symbols" style="display:block;float:left;min-width:0cm">•</span>  Autonomous quality assurance;<span class="odfLiEnd"/> </p></li><li><p class="List_20_1" style="margin-left:0.635cm;"><span class="Numbering_20_Symbols" style="display:block;float:left;min-width:0cm">•</span>  Cost saving.<span class="odfLiEnd"/> </p></li></ul><h2 class="Heading_20_2"><a id="a_1_3__Outdoor_Trails"><span>1.3 </span></a><a name="__RefHeading__1647_378428891"/>Outdoor Trails</h2><p class="P1">An outdoor sportsperson, e.g. snowboarder or cyclist, is equipped with a helmet-cam and/or mobile phone to record video footage and GPS data. They set off to explore an interesting area, e.g. off-piste or on mountain trails, to find new challenges and hone their sporting skills. The outing is a great success, as they discover new routes and other areas they would like to explore in future, chatting to the camera as they go.</p><p class="P1">They post their video to a website and share their experience with the online community, so viewers can quickly identify the locations of particularly interesting and challenging sections of the trail which are featured. Using the synchronised map view in their browser, community members can easily see where they need to go in order to try it for themselves.</p><p class="P1">The operator has been able to fully engage in their sporting activity, without making any written notes, while simultaneously recording the details needed to guide others to the same locations. Their changing location over time can also be used to calculate speed and distance information.</p><ul><li><p class="List_20_1" style="margin-left:0.635cm;"><span class="Numbering_20_Symbols" style="display:block;float:left;min-width:0cm">•</span>  Non-invasive capture;<span class="odfLiEnd"/> </p></li><li><p class="List_20_1" style="margin-left:0.635cm;"><span class="Numbering_20_Symbols" style="display:block;float:left;min-width:0cm">•</span>  Information sharing;<span class="odfLiEnd"/> </p></li><li><p class="List_20_1" style="margin-left:0.635cm;"><span class="Numbering_20_Symbols" style="display:block;float:left;min-width:0cm">•</span>  Speed and distance calculation.<span class="odfLiEnd"/> </p></li></ul><h2 class="Heading_20_2"><a id="a_1_4__TV_Sports_Coverage"><span>1.4 </span></a><a name="__RefHeading__1649_378428891"/>TV Sports Coverage</h2><p class="P1">A TV production company is covering a sports event that takes place over a large area, e.g. rallying, road cycling or sailing, using a number of mobile video devices including competitor cams, e.g. dash cams or helmet cams, and drones to provide shots of inaccessible areas, e.g. remote terrain or over water.</p><p class="P1">Feeds from all the cameras are streamed to the production control room, where their geolocation data are combined on a map showing the locations of every competitor and camera, each labelled for easy identification. The live map enables the director to quickly choose the best shot and anticipate where and when to deploy their drone cameras to catch competitors at critical locations on the course as the competition develops in real time.</p><p class="P1">Multiple operators can function concurrently, both autonomously and under central direction. Mobile assets can be monitored and deployed from an operations centre to provide optimum coverage of the developing live event.</p><ul><li><p class="List_20_1" style="margin-left:0.635cm;"><span class="Numbering_20_Symbols" style="display:block;float:left;min-width:0cm">•</span>  Multiple mobile video devices;<span class="odfLiEnd"/> </p></li><li><p class="List_20_1" style="margin-left:0.635cm;"><span class="Numbering_20_Symbols" style="display:block;float:left;min-width:0cm">•</span>  Real time asset management.<span class="odfLiEnd"/> </p></li></ul><h2 class="Heading_20_2"><a id="a_1_5__Proxy_Explorer"><span>1.5 </span></a><a name="__RefHeading__1651_378428891"/>Proxy Explorer</h2><p class="P1">Important details of a remote area have been captured on video. It is not possible to revisit the location for safety reasons or because it has physically changed in the intervening time. Footage can be retrospectively geotagged against a concurrent map to allow the viewer to better interpret and identify features seen in the footage. Explanatory annotations can be added to the video-map track to help future viewers' understanding and aggregate the collective analysis.</p><p class="P1">Multiple operators can contribute their observations to provide a group analysis, iteratively adding new details and discarding out-of-date information. Experts can offer insight about filmed locations, which would otherwise be inaccessible to them.</p><ul><li><p class="List_20_1" style="margin-left:0.635cm;"><span class="Numbering_20_Symbols" style="display:block;float:left;min-width:0cm">•</span>  Remote analysis of inaccessible locations;<span class="odfLiEnd"/> </p></li><li><p class="List_20_1" style="margin-left:0.635cm;"><span class="Numbering_20_Symbols" style="display:block;float:left;min-width:0cm">•</span>  Knowledge aggregation and sharing for archive footage.<span class="odfLiEnd"/> </p></li></ul><h2 class="Heading_20_2"><a id="a_1_6__Treasure_Hunt"><span>1.6 </span></a><a name="__RefHeading__1653_378428891"/>Treasure Hunt</h2><p class="P1">A TV production company designs a new game show which involves competitors searching for targets across a wide area, with an operations centre remotely monitoring their progress and providing updates. Competitors are equipped with body- or helmet-cams to relay footage of their view.</p><p class="P1">Geolocation context allow central operators to better understand the participants' actions and to remotely direct them more efficiently. Competitors' positions can displayed to the TV audience on annotated 2D- or 3D-maps for clearer presentation.</p><ul><li><p class="List_20_1" style="margin-left:0.635cm;"><span class="Numbering_20_Symbols" style="display:block;float:left;min-width:0cm">•</span>  Speed and distance calculation;<span class="odfLiEnd"/> </p></li><li><p class="List_20_1" style="margin-left:0.635cm;"><span class="Numbering_20_Symbols" style="display:block;float:left;min-width:0cm">•</span>  Knowledge aggregation and sharing for real-time footage.<span class="odfLiEnd"/> </p></li></ul><h2 class="Heading_20_2"><a id="a_1_7__Swarm_Monitoring"><span>1.7 </span></a><a name="__RefHeading__1655_378428891"/>Swarm Monitoring</h2><p class="P1">A swarm of drones is deployed to perform a task, and their operations are monitored centrally. Geolocation details of the swarm are automatically collated and broadcast to the drone pilots, showing the locations of all the drones and each is circled with a suitable safety zone to warn their operators in case two units find themselves flying in close proximity.</p><p class="P1">Pilots are safely able to operate either autonomously or under the direction of central control. Extra zonal information can be added to the operators' maps to show the outer perimeter of their operating area and warn of fixed aerial hazards, e.g. a radio mast, or transient hazards, e.g. a helicopter.</p><ul><li><p class="List_20_1" style="margin-left:0.635cm;"><span class="Numbering_20_Symbols" style="display:block;float:left;min-width:0cm">•</span>  Static and dynamic hazard indication;<span class="odfLiEnd"/> </p></li><li><p class="List_20_1" style="margin-left:0.635cm;"><span class="Numbering_20_Symbols" style="display:block;float:left;min-width:0cm">•</span>  Central swarm monitoring;<span class="odfLiEnd"/> </p></li><li><p class="List_20_1" style="margin-left:0.635cm;"><span class="Numbering_20_Symbols" style="display:block;float:left;min-width:0cm">•</span>  Autonomous swarm monitoring.<span class="odfLiEnd"/> </p></li></ul><h1 class="Heading_20_1"><a id="a_2__State_of_the_Art"><span>2 </span></a><a name="__RefHeading__1657_378428891"/>State of the Art</h1><p class="P4">No standard format currently exists by which to synchronise geolocation data with video. Though many formats exist to capture the two data streams separately, e.g. MPEG for video and GPX for geolocation, there is no standard which addresses the issue of video playback time synchronisation with geolocation.</p><h2 class="Heading_20_2"><a id="a_2_1__Current_Solutions"><span>2.1 </span></a><a name="__RefHeading__1659_378428891"/>Current Solutions</h2><p class="P1">Different video camera manufacturers have taken different approaches, resulting in a number of non-standard solutions including embedding geolocation data within the MPEG stream (either at frame level or in metadata) or recording a separate geolocation file in a proprietary format alongside the associated MPEG file. From a hardware perspective, a few high-end cameras provide geotagging out of the box and all require an additional add-on to support this feature.</p><p class="P1">In sharp contrast, still photos have a well-established geotagging standard called Exif, which was published by the Japan Electronic Industries Development Association (JEIDA) in 1995 and defines a metadata tag to embed geolocation data within TIFF and JPEG images. This is widely supported by manufacturers of photographic equipment and software worldwide, including low-end smartphones, making this feature cheap and accessible to the public.</p><h2 class="Heading_20_2"><a id="a_2_2__Growing_Requirement"><span>2.2 </span></a><a name="__RefHeading__1661_378428891"/>Growing Requirement</h2><p class="P1">Historically, there has been no requirement for a comparable video standard, but the urgency for such a standard is growing fast due to the emerging markets for 'mobile video devices,' e.g. drones, dash-, body- and helmet-cams, as well as the rise in high-quality video and geolocation support in the global smartphone market.</p><h2 class="Heading_20_2"><a id="a_2_3__Accessible_Standard_Opportunity"><span>2.3 </span></a><a name="__RefHeading__1663_378428891"/>Accessible Standard Opportunity</h2><p class="P1">Using current W3C recommendations, it is possible for an able programmer to synchronise video-geolocation 'metadata' with a &lt;video&gt; element using a &lt;track&gt; child element. However, this is a non-trivial development task which requires an understanding of the video DOM events and Javascript file handling, making it inaccessible to the vast majority of web users. In addition, video map tracks are a clearly identified metadata subclass, which could be isolated in a similar way to video text tracks.</p><p class="Text_20_body"><span class="T3">Establishing a standard file format would allow interoperability and information sharing between the </span><span class="T3">emergency services, police and other mobile video device users, e.g. drone pilots, giving cheaper and easier access to this important source of information. If web browsers supported video geotagging natively using this file format, it would also become accessible to most web users. Current low-end smartphones already provide suitable hardware to concurrently capture video and geolocation streams, which would make this technology easily accessible to the general public, and encourage the user and developer communities to grow rapidly.</span></p><h1 class="Heading_20_1"><a id="a_3__Proposed_Solution"><span>3 </span></a><a name="__RefHeading__1665_378428891"/>Proposed Solution</h1><p class="P1">This proposal constitutes a lightweight markup language to synchronise video with geolocation data for display on electronic maps, e.g. Google Maps. It offers presentational control of the map display, e.g. pan and zoom, and annotation to highlight map features to the viewer, e.g. markers and labels.</p><p class="P1">WebVMT (Web Video Map Tracks) format is intended for marking up external map track resources, and its main use is for files synchronising video content with an annotated map presentation. Ideas have been borrowed from existing W3C standards, including WebVTT's HTML binding and its block and cue structures, and SVG's approach to drawing and animation, in order to display output on an electronic map.</p><p class="P1">The protocol mimics WebVTT's structure and syntax for video synchronisation, with cue details listed in an accessible text-based file linked to the &lt;video&gt; DOM element by a child &lt;track&gt; element in an HTML document.</p><p class="P13">&lt;!doctype html&gt;</p><p class="P13">&lt;html&gt;</p><p class="P13">  &lt;head&gt;</p><p class="P13">    &lt;title&gt;WebVMT Basic Example&lt;/title&gt;</p><p class="P13">  &lt;/head&gt;</p><p class="P13">  &lt;body&gt;</p><p class="P13">    &lt;!-- Video display --&gt;</p><p class="P13">    &lt;video controls width="640" height="360"&gt;</p><p class="P13">      &lt;source src="video.mp4" type="video/mp4"&gt;</p><p class="P13">      &lt;track src="maptrack.vmt" kind="map"&gt;</p><p class="P13">      Your browser does not support the video tag.</p><p class="P13">    &lt;/video&gt;</p><p class="P13">    &lt;!-- Map display --&gt;</p><p class="P13">    &lt;div id="vmt-map" style="height: 360px; width:640px;"&gt;&lt;/div&gt;</p><p class="P13">  &lt;/body&gt;</p><p class="P13">&lt;/html&gt;</p><h2 class="Heading_20_2"><a id="a_3_1__Map_Cues"><span>3.1 </span></a><a name="__RefHeading__1667_378428891"/>Map Cues</h2><p class="P1">Map cues display their payload between a start time and end time.</p><p class="P1">The end cue time may be omitted to signify the end time of the video, which may be unknown in the case of streamed video.</p><h3 class="Heading_20_3"><a id="a_3_1_1__Example_1__Hello_World"><span>3.1.1 </span></a><a name="__RefHeading__1669_378428891"/>Example 1: Hello World</h3><p class="P1">Here is a sample VMT file with a cue highlighting Tower Bridge in London on a static map.</p><p class="P12">WEBVMT</p><p class="P12"> </p><p class="P12">MAP {</p><p class="P12">  tile-url: https://api2.ordnancesurvey.co.uk/mapping_api/v1/</p><p class="P12">    service/zxy/EPSG%3A3857/Outdoor%203857/\{z}/{x}/{y}.png?</p><p class="P12">    key=VALID_OS_KEY;</p><p class="P12">  div-id: vmt-map;</p><p class="P12">  centre: <span class="T1">51.506 -0.076</span>;</p><p class="P12">  zoom: 16;</p><p class="P12">}</p><p class="P12"> </p><p class="P12">00:00:02.000 --&gt; 00:00:05.000</p><p class="P12">&lt;moveto <span class="T1">latLng="51.504362 -0.076153"/&gt;</span></p><p class="P13">&lt;lineto latLng="51.506646 -0.074651"/&gt;</p><h3 class="Heading_20_3"><a id="a_3_1_2__Example_2__Map_Presentation"><span>3.1.2 </span></a><a name="__RefHeading__1671_378428891"/>Example 2: Map Presentation</h3><p class="P1">Cues also allow dynamic presentation to pan and zoom the map. This example focusses attention on the Tower of London.</p><p class="P1">Cues without end times are displayed until the end of the video, which may be at an unknown time in the case of a video stream.</p><p class="P12">WEBVMT</p><p class="P12"> </p><p class="P12">MAP {</p><p class="P12">  tile-url: https://api2.ordnancesurvey.co.uk/mapping_api/v1/</p><p class="P12">    service/zxy/EPSG%3A3857/Outdoor%203857/\{z}/{x}/{y}.png?</p><p class="P12">    key=VALID_OS_KEY;</p><p class="P12">  div-id: vmt-map;</p><p class="P12">  centre: <span class="T1">51.162 -0.143</span>;</p><p class="P12">  zoom: 10;</p><p class="P12">}</p><p class="P12"> </p><p class="P12">00:00:03.000 --&gt;</p><p class="P12">&lt;panto latLng="51.508 -0.077" end="00:00:05.000"<span class="T1">/&gt;</span></p><p class="P13"> </p><p class="P12">00:00:06.000 --&gt;</p><p class="P11"><span class="T5">&lt;zoom level="16"</span><span class="T4">/&gt;</span></p><h2 class="Heading_20_2"><a id="a_3_2__Comments"><span>3.2 </span></a><a name="__RefHeading__1673_378428891"/>Comments</h2><p class="P1">Comments are blocks that are preceded by a blank line, start with the word "NOTE" (followed by a space or newline), and end at the first blank line.</p><h3 class="Heading_20_3"><a id="a_3_2_1__Example_3__Comment_Block__as_WebVTT_"><span>3.2.1 </span></a><a name="__RefHeading__1675_378428891"/>Example 3: Comment Block (as WebVTT)</h3><p class="P1"><span class="T2">This example highlights </span>London landmarks near Tower Bridge.</p><p class="P12">WEBVMT</p><p class="P12"> </p><p class="P12">NOTE Map config</p><p class="P12"> </p><p class="P12">MAP {</p><p class="P12">  tile-url: https://api2.ordnancesurvey.co.uk/mapping_api/v1/</p><p class="P12">    service/zxy/EPSG%3A3857/Outdoor%203857/\{z}/{x}/{y}.png?</p><p class="P12">    key=VALID_OS_KEY;</p><p class="P12">  div-id: vmt-map;</p><p class="P12">  centre: <span class="T1">51.506 -0.076</span>;</p><p class="P12">  zoom: 16;</p><p class="P12">}</p><p class="P12"> </p><p class="P12">NOTE Tower Bridge</p><p class="P12"> </p><p class="P12">00:00:01.000 --&gt; 00:00:05.000</p><p class="P12">&lt;moveto <span class="T1">latLng="51.504362 -0.076153"/&gt;</span></p><p class="P13">&lt;lineto latLng="51.506646 -0.074651"/&gt;</p><p class="P13"> </p><p class="P13">NOTE City Hall</p><p class="P13"> </p><p class="P13">00:00:02.000 --&gt;</p><p class="P13">&lt;circle latLng="51.504789 -0.078642" rad="20"/&gt;</p><p class="P13"> </p><p class="P13">NOTE Tower Of London</p><p class="P13">This line is also part of the comment</p><p class="P13"> </p><p class="P13">00:00:03.000 --&gt; 00:00:04.000</p><p class="P13">&lt;polygon coords="51.507193 -0.074844, 51.508756 -0.074716,</p><p class="P13">  51.509036 -0.075638, 51.508929 -0.077162, 51.507727 -0.077848,</p><p class="P13">  51.507220 -0.075767"/&gt;</p><h2 class="Heading_20_2"><a id="a_3_3__Styling"><span>3.3 </span></a><a name="__RefHeading__1677_378428891"/>Styling</h2><p class="P1">Display style is controlled by CSS, which may be embedded in HTML or within the WebVMT file.</p><h3 class="Heading_20_3"><a id="a_3_3_1__Example_4__CSS_Style_in_HTML"><span>3.3.1 </span></a><a name="__RefHeading__1679_378428891"/>Example 4: CSS Style in HTML</h3><p class="P1">In this example, an HTML page has a CSS style sheet in a &lt;style&gt; element that styles map cues for the video, e.g. drawing lines in red.</p><p class="P13">&lt;!doctype html&gt;</p><p class="P13">&lt;html&gt;</p><p class="P13">  &lt;head&gt;</p><p class="P13">    &lt;title&gt;WebVMT Style Example&lt;/title&gt;</p><p class="P13">    &lt;style&gt;</p><p class="P13">      video::cue-map {</p><p class="P13">        stroke-colour: red;</p><p class="P13">        stroke-opacity: 0.9;</p><p class="P13">      }</p><p class="P13">    &lt;/style&gt;</p><p class="P13">  &lt;/head&gt;</p><p class="P13">  &lt;body&gt;</p><p class="P13">    &lt;video controls width="640" height="360"&gt;</p><p class="P13">      &lt;source src="video.mp4" type="video/mp4"&gt;</p><p class="P13">      &lt;track src="maptrack.vmt" kind="map"&gt;</p><p class="P13">      Your browser does not support the video tag.</p><p class="P13">    &lt;/video&gt;</p><p class="P13">    &lt;div id="vmt-map" style="height: 360px; width:640px;"&gt;&lt;/div&gt;</p><p class="P13">  &lt;/body&gt;</p><p class="P13">&lt;/html&gt;</p><h3 class="Heading_20_3"><a id="a_3_3_2__Example_5__CSS_Style_Block__as_WebVTT_"><span>3.3.2 </span></a><a name="__RefHeading__1681_378428891"/>Example 5: CSS Style Block (as WebVTT)</h3><p class="P3">CSS style sheets can also be embedded in WebVMT files themselves. Style blocks are placed after any headers but before the first cue, and start with the line "STYLE".</p><p class="P3">Comment blocks can be interleaved with style blocks.</p><p class="P13">WEBVMT</p><p class="P13"> </p><p class="P12">MAP {</p><p class="P12">  tile-url: https://api2.ordnancesurvey.co.uk/mapping_api/v1/</p><p class="P12">    service/zxy/EPSG%3A3857/Outdoor%203857/\{z}/{x}/{y}.png?</p><p class="P12">    key=VALID_OS_KEY;</p><p class="P12">  div-id: vmt-map;</p><p class="P12">  centre: 51.478 -0.001;</p><p class="P12">  zoom: 18;</p><p class="P13">}</p><p class="P13"> </p><p class="P13">STYLE</p><p class="P13">::cue-map {</p><p class="P13">  stroke-colour: red;</p><p class="P13">}</p><p class="P13"> </p><p class="P13">NOTE Comments are allowed between style blocks</p><p class="P13"> </p><p class="P13">STYLE</p><p class="P13">::cue-map {</p><p class="P13">  stroke-opacity: 0.9;</p><p class="P13">}</p><p class="P13"> </p><p class="P13">NOTE Prime Meridian marker</p><p class="P13"> </p><p class="P13">00:00:00.000 --&gt;</p><p class="P13">&lt;moveto latLng="51.477901 -0.001466"/&gt;</p><p class="P13">&lt;lineto latLng="51.477946 -0.001466"/&gt;</p><p class="P13"> </p><p class="P13">NOTE Style blocks may not appear after the first cue</p><h2 class="Heading_20_2"><a id="a_3_4__Animation"><span>3.4 </span></a><a name="__RefHeading__1683_378428891"/>Animation</h2><p class="P1">Map annotations may be animated using an &lt;<span class="T6">animate&gt;</span> element, in a similar way to SVG.</p><p class="P1">Map paths have additional properties to other annotations, including a unique identifier and a drawing animation which can be controlled separately for distance calculation purposes.</p><h3 class="Heading_20_3"><a id="a_3_4_1__Example_6__Animated_Path"><span>3.4.1 </span></a><a name="__RefHeading__1685_378428891"/>Example 6: Animated Path</h3><p class="P1">A path typically indicates a mobile camera's route, which is defined by a &lt;<span class="T6">moveto&gt;</span> element followed by a sequence of &lt;<span class="T6">lineto&gt;</span> elements, and may include multiple discrete segments separated by &lt;<span class="T6">moveto&gt;</span> elements.</p><p class="P1">A path should be assigned an identifier using the '<span class="T6">pathId'</span> attribute to discriminate it from other paths. This allow multiple paths to be uniquely identified, for different paths to be styled in different ways, e.g. colour, and also enables speed and distance calculations to be performed for each path during playback.</p><p class="P1">In this example, an animated path is traced from London to Brighton:</p><p class="P12">WEBVMT</p><p class="P12"> </p><p class="P12">NOTE Map config</p><p class="P12"> </p><p class="P12">MAP {</p><p class="P12">  tile-url: https://api2.ordnancesurvey.co.uk/mapping_api/v1/</p><p class="P12">    service/zxy/EPSG%3A3857/Outdoor%203857/\{z}/{x}/{y}.png?</p><p class="P12">    key=VALID_OS_KEY;</p><p class="P12">  div-id: vmt-map;</p><p class="P12">  centre: 51.1618 -0.1428;</p><p class="P12">  zoom: 10;</p><p class="P12">}</p><p class="P12"> </p><p class="P12">NOTE London overview</p><p class="P12"> </p><p class="P12">00:00:01.000 --&gt;</p><p class="P12">&lt;panto latLng="51.4952 -0.1441"/&gt;</p><p class="P12"> </p><p class="P12">00:00:02.000 --&gt;</p><p class="P12">&lt;zoom level="13"/&gt;</p><p class="P12"/><p class="P12">NOTE From London Victoria...</p><p class="P12"> </p><p class="P12">00:00:03.000 --&gt;</p><p class="P12">&lt;panto latLng="50.830553 -0.141706" end="00:00:25.000"/&gt;</p><p class="P12">&lt;moveto latLng="51.494477 -0.144753" pathId="cam1"/&gt;</p><p class="P12">&lt;lineto latLng="51.155958 -0.16089" pathId="cam1"</p><p class="P12">  end="00:00:10.000"/&gt;</p><p class="P12"> </p><p class="P12">NOTE ...via Gatwick Airport...</p><p class="P12"> </p><p class="P12">00:00:10.000 --&gt;</p><p class="P12">&lt;lineto latLng="50.830553 -0.141706" pathId="cam1"</p><p class="P12">  end="00:00:25.000"/&gt;</p><p class="P12"> </p><p class="P12">NOTE ...to Brighton (at 00:00:25.000)</p><p class="P12"> </p><p class="P12">00:00:27.000 --&gt;</p><p class="P12">&lt;zoom level="10"/&gt;</p><h3 class="Heading_20_3"><a id="a_3_4_2__Example_7__Animated_Annotation"><span>3.4.2 </span></a><a name="__RefHeading__1687_378428891"/>Example 7: Animated Annotation</h3><p class="P1">This example tracks a drone with a circular 10-metre safety zone around it:</p><p class="P12">WEBVMT</p><p class="P12"> </p><p class="P12">NOTE Map config</p><p class="P12"> </p><p class="P12">MAP {</p><p class="P12">  tile-url: https://api2.ordnancesurvey.co.uk/mapping_api/v1/</p><p class="P12">    service/zxy/EPSG%3A3857/Outdoor%203857/\{z}/{x}/{y}.png?</p><p class="P12">    key=VALID_OS_KEY;</p><p class="P12">  div-id: vmt-map;</p><p class="P12">  centre: 51.0130 -0.0015;</p><p class="P12">  zoom: 10;</p><p class="P12">}</p><p class="P12"> </p><p class="P12">NOTE Drone starts at (51.0130, -0.0015)</p><p class="P12"> </p><p class="P12">00:00:05.000 --&gt;</p><p class="P12">&lt;panto latLng="51.0070 -0.0020" end="00:00:25.000"/&gt;</p><p class="P12">&lt;moveto latLng="51.0130 -0.0015" pathId="drone1"/&gt;</p><p class="P12">&lt;lineto latLng="51.0090 -0.0017" pathId="drone1"</p><p class="P12">  end="00:00:10.000"/&gt;</p><p class="P12"> </p><p class="P12">00:00:05.000 --&gt; 00:00:10.000</p><p class="P12">&lt;circle latLng="51.0130 -0.0015" rad="10"&gt;</p><p class="P12">  &lt;animate attribName="latLng" to="51.0090 -0.0017" </p><p class="P12">    end="00:00:10.000"/&gt;</p><p class="P12">&lt;/circle&gt;</p><p class="P12"> </p><p class="P12">NOTE Drone arrives at (51.0090, -0.0017)</p><p class="P12"> </p><p class="P12">00:00:10.000 --&gt;</p><p class="P12">&lt;lineto latLng="51.0070 -0.0020" pathId="drone1"</p><p class="P12">  end="00:00:25.000" /&gt;</p><p class="P12">&lt;circle latLng="51.0090 -0.0017" rad="10"&gt;</p><p class="P12">  &lt;animate attribName="latLng" to="51.0070 -0.0020"</p><p class="P12">    end="00:00:25.000"/&gt;</p><p class="P12">&lt;/circle&gt;</p><p class="P12"> </p><p class="P12">NOTE Drone ends at (51.0070, -0.0020)</p><h1 class="Heading_20_1"><a id="a_4__Known_Issues"><span>4 </span></a><a name="__RefHeading__1689_378428891"/>Known Issues</h1><h2 class="Heading_20_2"><a id="a_4_1__Planned_Features"><span>4.1 </span></a><a name="__RefHeading__1691_378428891"/>Planned Features</h2><p class="P1">This section lists potential features which have been identified during the development process, but have not yet matured to a full design specification.</p><p class="P1">Features which appear in this section warrant further investigation, but are not guaranteed to appear in the final specification.</p><h3 class="Heading_20_3"><a id="a_4_1_1__Marker"><span>4.1.1 </span></a><a name="__RefHeading__1693_378428891"/>Marker</h3><p class="P1">An image linked to and displayed at an offset from a geolocation.</p><h3 class="Heading_20_3"><a id="a_4_1_2__Label"><span>4.1.2 </span></a><a name="__RefHeading__1695_378428891"/>Label</h3><p class="P1">A text string linked to and displayed at an offset from a geolocation.</p><h3 class="Heading_20_3"><a id="a_4_1_3__Tile_URL_Shortcut"><span>4.1.3 </span></a><a name="__RefHeading__1697_378428891"/>Tile URL Shortcut</h3><p class="P1">Shortcuts to popular tile URLs.</p><h3 class="Heading_20_3"><a id="a_4_1_4__Layer"><span>4.1.4 </span></a><a name="__RefHeading__1804_378428891"/>Layer</h3><p class="P1">Syntax to allow more than one layer of map tiles to be specified, e.g. Google Maps includes 'map' and 'satellite' layers.</p><h3 class="Heading_20_3"><a id="a_4_1_5__Multiple_APIs"><span>4.1.5 </span></a><a name="__RefHeading__1806_378428891"/>Multiple APIs</h3><p class="P1">The current tech demo is based on the Leaflet API, but should be broadened to support other web map APIs, e.g. Open Layers and Google Maps.</p><p class="P1">A hot-swap feature would allow users to switch API on the fly to take advantage of the unique features supported by different APIs, e.g. Google Streetview.</p><h3 class="Heading_20_3"><a id="a_4_1_6__Camera_Direction"><span>4.1.6 </span></a><a name="__RefHeading__1808_378428891"/>Camera Direction</h3><p class="P10">Camera orientation may not match the direction of travel, or may be dynamic, e.g. for Augmented Reality.</p><p class="P1"> </p></body></html>
